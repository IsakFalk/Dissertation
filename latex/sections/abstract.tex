In this thesis we will explore the role of latent variable models in NMT (neural
machine translation). We will consider newly published models such as AUTR which
writes to a canvas, essentially using an external memory in extension to a
recurrent neural network.